{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Batwan01/2024-Challenge/blob/main/history/24-9-5/MLP5%2BPReLU_base_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "GBmt3kLNeFAS",
        "outputId": "840fdc73-21c3-438e-d5a4-ec9cd0f01b59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.6-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.6-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, ElasticNet, Lars, LassoLars, OrthogonalMatchingPursuit, BayesianRidge, ARDRegression, PassiveAggressiveRegressor, RANSACRegressor, HuberRegressor)\n",
        "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "\n",
        "# 재현 가능성을 위한 시드 고정\n",
        "RANDOM_SEED = 18\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n"
      ],
      "metadata": {
        "id": "8N5kdRfjFDiC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "h66mrXCydXAy",
        "outputId": "5b231d24-0fae-41e2-ffe5-18f2fedf1386",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 데이터 로드 및 전처리\n",
        "train_csv_path = \"/content/drive/MyDrive/Colab Notebooks/contest/samsung/train.csv\"\n",
        "test_csv_path = \"/content/drive/MyDrive/Colab Notebooks/contest/samsung/test.csv\"\n",
        "train = pd.read_csv(train_csv_path)\n",
        "test = pd.read_csv(test_csv_path)\n",
        "com = pd.concat([train, test])\n",
        "com = com.drop(['x_2', 'x_6'], axis=1)\n",
        "\n",
        "train_data = com[:40118]\n",
        "X_test_df = com[40118:].drop('y', axis=1).iloc[:, 1:]\n",
        "\n",
        "# 입력 데이터와 라벨 분리\n",
        "X_train_df = train_data.drop(['ID', 'y'], axis=1)\n",
        "y_train_df = train_data['y']\n",
        "\n",
        "# 스무딩 처리 (여기서는 가정된 변수명을 그대로 사용함)\n",
        "X_train = pd.get_dummies(X_train_df, drop_first=True)\n",
        "X_test = pd.get_dummies(X_test_df, drop_first=True)\n",
        "\n",
        "# 스케일링 적용\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(X_test.shape)\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "id": "9KIgBfH9dT7t",
        "outputId": "71f33b55-a8e2-4f23-bbc8-fc4ada60276d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4986, 9)\n",
            "(40118, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stacking_ml_datasets(model, X_train_n, y_train_n, X_test_n, n_folds=5, fitting=True):\n",
        "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=RANDOM_SEED)\n",
        "\n",
        "    train_fold_pred = np.zeros((X_train_n.shape[0], y_train_n.shape[1]))\n",
        "    test_pred = np.zeros((X_test_n.shape[0], y_train_n.shape[1], n_folds))\n",
        "\n",
        "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n, y_train_n)):\n",
        "        X_tr = X_train_n[train_index]\n",
        "        y_tr = y_train_n[train_index].ravel()  # y_train을 1차원 배열로 변환\n",
        "        X_te = X_train_n[valid_index]\n",
        "\n",
        "        if fitting:\n",
        "            model.fit(X_tr, y_tr)\n",
        "\n",
        "        train_pred = model.predict(X_te)\n",
        "        if train_pred.ndim == 1:\n",
        "            train_pred = train_pred.reshape(-1, 1)\n",
        "        train_fold_pred[valid_index] = train_pred\n",
        "\n",
        "        test_fold_pred = model.predict(X_test_n)\n",
        "        if test_fold_pred.ndim == 1:\n",
        "            test_fold_pred = test_fold_pred.reshape(-1, 1)\n",
        "        test_pred[:, :, folder_counter] = test_fold_pred\n",
        "\n",
        "    test_pred_mean = np.mean(test_pred, axis=2)\n",
        "\n",
        "    return train_fold_pred, test_pred_mean\n"
      ],
      "metadata": {
        "id": "gOW82JxMduWU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NRMSE 계산 함수\n",
        "def lg_nrmse(gt, preds):\n",
        "    all_nrmse = []\n",
        "    for idx in range(gt.shape[1]):\n",
        "        rmse = mean_squared_error(gt[:,idx], preds[:,idx], squared=False)\n",
        "        nrmse = rmse / np.mean(np.abs(gt[:,idx]))\n",
        "        all_nrmse.append(nrmse)\n",
        "    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:14])\n",
        "    return score\n",
        "\n",
        "# 여러 모델 정의\n",
        "base_ml = {\n",
        "    'Linear Regression': LinearRegression(n_jobs=-1),\n",
        "    'Ridge': Ridge(random_state=RANDOM_SEED),\n",
        "    'Lasso': Lasso(random_state=RANDOM_SEED),\n",
        "    'ElasticNet': ElasticNet(random_state=RANDOM_SEED),\n",
        "    'Lars': Lars(random_state=RANDOM_SEED),\n",
        "    'LassoLars': LassoLars(random_state=RANDOM_SEED),\n",
        "    'OMP': OrthogonalMatchingPursuit(),\n",
        "    'BayesianRidge': MultiOutputRegressor(BayesianRidge()),\n",
        "    'ARDRegression': MultiOutputRegressor(ARDRegression()),\n",
        "    'PAR': MultiOutputRegressor(PassiveAggressiveRegressor(random_state=RANDOM_SEED)),\n",
        "    'RANSAC': RANSACRegressor(random_state=RANDOM_SEED),\n",
        "    'Huber': MultiOutputRegressor(HuberRegressor()),\n",
        "    'KNN': KNeighborsRegressor(n_jobs=-1),\n",
        "    'DecisionTree': DecisionTreeRegressor(random_state=RANDOM_SEED),\n",
        "    'ExtraTree': ExtraTreeRegressor(random_state=RANDOM_SEED),\n",
        "    'Bagging': BaggingRegressor(n_jobs=-1, random_state=RANDOM_SEED),\n",
        "    'ExtraTrees': ExtraTreesRegressor(n_jobs=-1, random_state=RANDOM_SEED),\n",
        "    'RandomForest': RandomForestRegressor(n_jobs=-1, random_state=RANDOM_SEED),\n",
        "    'HistGradientBoosting': MultiOutputRegressor(HistGradientBoostingRegressor(random_state=RANDOM_SEED)),\n",
        "    'XGBoost': XGBRegressor(tree_method='gpu_hist', gpu_id=0, n_jobs=-1, random_state=RANDOM_SEED),\n",
        "    'LightGBM': MultiOutputRegressor(LGBMRegressor(n_jobs=-1, random_state=RANDOM_SEED)),\n",
        "    'CatBoost': MultiOutputRegressor(CatBoostRegressor(task_type=\"GPU\", devices='0', verbose=False, random_state=RANDOM_SEED))\n",
        "}"
      ],
      "metadata": {
        "id": "3R0A6slmd06P"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 스태킹 데이터셋 생성\n",
        "meta_ml_X_train = []\n",
        "meta_ml_X_test = []\n",
        "n_folds = 5\n",
        "for name, model in base_ml.items():\n",
        "    print(f'Running {name}...')\n",
        "    temp_X_train, temp_X_test = get_stacking_ml_datasets(model, X_train, y_train_df.values.reshape(-1, 1), X_test, n_folds)\n",
        "    meta_ml_X_train.append(temp_X_train)\n",
        "    meta_ml_X_test.append(temp_X_test)\n",
        "\n",
        "# 스태킹 데이터 결합\n",
        "meta_ml_X_train = np.mean(meta_ml_X_train, axis=0)\n",
        "meta_ml_X_test = np.mean(meta_ml_X_test, axis=0)"
      ],
      "metadata": {
        "id": "V7T9j-izdw3C",
        "outputId": "cb93fd44-eb65-4847-afab-ca8b8103e80c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Linear Regression...\n",
            "Running Ridge...\n",
            "Running Lasso...\n",
            "Running ElasticNet...\n",
            "Running Lars...\n",
            "Running LassoLars...\n",
            "Running OMP...\n",
            "Running BayesianRidge...\n",
            "Running ARDRegression...\n",
            "Running PAR...\n",
            "Running RANSAC...\n",
            "Running Huber...\n",
            "Running KNN...\n",
            "Running DecisionTree...\n",
            "Running ExtraTree...\n",
            "Running Bagging...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:509: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:509: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:509: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:509: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:509: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running ExtraTrees...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running RandomForest...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running HistGradientBoosting...\n",
            "Running XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [14:04:01] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [14:04:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [14:04:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [14:04:02] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [14:04:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running LightGBM...\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003024 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2295\n",
            "[LightGBM] [Info] Number of data points in the train set: 32094, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 83.638855\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003178 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2295\n",
            "[LightGBM] [Info] Number of data points in the train set: 32094, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 83.629973\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002568 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2295\n",
            "[LightGBM] [Info] Number of data points in the train set: 32094, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 83.637913\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002462 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2295\n",
            "[LightGBM] [Info] Number of data points in the train set: 32095, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 83.637059\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003384 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2295\n",
            "[LightGBM] [Info] Number of data points in the train set: 32095, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 83.647203\n",
            "Running CatBoost...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 메타 모델 학습 및 예측\n",
        "meta_clf = LinearRegression()\n",
        "meta_clf.fit(meta_ml_X_train, y_train_df)\n",
        "prediction = meta_clf.predict(meta_ml_X_test)\n",
        "\n",
        "# 결과값을 반올림하여 처리\n",
        "result = prediction.round(3)"
      ],
      "metadata": {
        "id": "_wyKl6xud5vs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과 저장 (1차원 배열 처리)\n",
        "submission = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/contest/samsung/sample_submission.csv\")\n",
        "\n",
        "# 'y' 열에 예측 결과 할당 (결과가 1차원 배열일 때)\n",
        "submission['y'] = result  # 'y' 컬럼에 1차원 예측 결과를 넣음\n",
        "\n",
        "# CSV 파일로 저장\n",
        "submission.to_csv(\"/content/drive/MyDrive/Colab Notebooks/contest/samsung/result/Stacking_Predictions.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "_DCJpiyBd8AI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_non_matching_ids(file1, file2):\n",
        "    # 두 개의 CSV 파일을 읽어옴\n",
        "    df1 = pd.read_csv(file1)\n",
        "    df2 = pd.read_csv(file2)\n",
        "\n",
        "    # y 값 기준으로 내림차순 정렬\n",
        "    df1_sorted = df1.sort_values(by='y', ascending=False)\n",
        "    df2_sorted = df2.sort_values(by='y', ascending=False)\n",
        "\n",
        "    # file1의 상위 10% 항목 계산\n",
        "    top_10_percent_count = int(len(df1_sorted) * 0.1)\n",
        "    top_10_percent_ids_df1 = set(df1_sorted.head(top_10_percent_count)['ID'])\n",
        "\n",
        "    # file2의 상위 10% ID 추출\n",
        "    top_10_percent_ids_df2 = set(df2_sorted.head(top_10_percent_count)['ID'])\n",
        "\n",
        "    # file1의 상위 10% 중 file2의 상위 10%에 없는 ID 계산\n",
        "    non_matching_ids = top_10_percent_ids_df1 - top_10_percent_ids_df2\n",
        "    num_non_matching = len(non_matching_ids)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"file1의 상위 10% 항목 개수: {top_10_percent_count}\")\n",
        "    print(f\"file1의 상위 10% 중 file2에 없는 항목 개수: {num_non_matching}\")\n",
        "    print(f\"file1의 상위 10% 중 file2에 없는 항목 ID: {non_matching_ids}\")\n",
        "\n",
        "    return top_10_percent_count, num_non_matching, list(non_matching_ids)\n",
        "\n",
        "# 사용 예시\n",
        "file1 ='/content/drive/MyDrive/Colab Notebooks/contest/samsung/MLP_Residual_Connection_drop_x2_x6(0.752).csv' # best 성능 파일\n",
        "file2 = '/content/drive/MyDrive/Colab Notebooks/contest/samsung/MLP_Residual_Connection_18.csv'\n",
        "file3 = '/content/drive/MyDrive/Colab Notebooks/contest/samsung/result/Stacking_Predictions.csv' # 측정하고자 하는 파일\n",
        "top_10_percent_count, num_non_matching, non_matching_ids = find_non_matching_ids(file1, file3)\n",
        "top_10_percent_count, num_non_matching, non_matching_ids = find_non_matching_ids(file2, file3)"
      ],
      "metadata": {
        "id": "F5K64efPqdRe",
        "outputId": "69226128-8fb6-4d27-f1b0-c6c51c83f659",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file1의 상위 10% 항목 개수: 498\n",
            "file1의 상위 10% 중 file2에 없는 항목 개수: 32\n",
            "file1의 상위 10% 중 file2에 없는 항목 ID: {'TEST_1978', 'TEST_3265', 'TEST_4828', 'TEST_1510', 'TEST_1178', 'TEST_0425', 'TEST_1309', 'TEST_1853', 'TEST_4876', 'TEST_3536', 'TEST_4070', 'TEST_0037', 'TEST_4154', 'TEST_0103', 'TEST_2220', 'TEST_2538', 'TEST_1574', 'TEST_1803', 'TEST_4033', 'TEST_4043', 'TEST_0635', 'TEST_4069', 'TEST_0898', 'TEST_1909', 'TEST_4179', 'TEST_0107', 'TEST_4738', 'TEST_0935', 'TEST_3718', 'TEST_2772', 'TEST_3512', 'TEST_4551'}\n",
            "file1의 상위 10% 항목 개수: 498\n",
            "file1의 상위 10% 중 file2에 없는 항목 개수: 35\n",
            "file1의 상위 10% 중 file2에 없는 항목 ID: {'TEST_1321', 'TEST_1978', 'TEST_3265', 'TEST_4828', 'TEST_1510', 'TEST_1178', 'TEST_0425', 'TEST_1309', 'TEST_1853', 'TEST_4876', 'TEST_3536', 'TEST_4070', 'TEST_0037', 'TEST_4154', 'TEST_0103', 'TEST_2220', 'TEST_2538', 'TEST_1574', 'TEST_4511', 'TEST_4043', 'TEST_4033', 'TEST_0635', 'TEST_0784', 'TEST_4069', 'TEST_2632', 'TEST_0898', 'TEST_1909', 'TEST_0107', 'TEST_4738', 'TEST_0935', 'TEST_4982', 'TEST_3718', 'TEST_2772', 'TEST_1792', 'TEST_2981'}\n"
          ]
        }
      ]
    }
  ]
}