{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2KZC-cmKREl"
      },
      "source": [
        "# Samsung AI Challenge : Black-box Optimization\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. 초기 세팅 (필수 실행)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CTNFa1kUiS8m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TSYWao-mdfy3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290dff04-65e5-4899-dd02-ee74cf1a606d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 재현 가능성을 위한 시드 고정\n",
        "RANDOM_SEED = 18\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Dataloader 시드 고정 (아직 사용 x)\n",
        "'''\n",
        "generator = torch.Generator()\n",
        "generator.manual_seed(RANDOM_SEED)\n",
        "\n",
        "def worker_init_fn(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "# DataLoader(worker_init_fn=worker_init_fn)\n",
        "'''\n",
        "\n",
        "# 데이터 경로 설정\n",
        "train_csv_path = \"/content/drive/MyDrive/Samsung_AI_challenge/Data/train.csv\"\n",
        "test_csv_path = \"/content/drive/MyDrive/Samsung_AI_challenge/Data/test.csv\"\n",
        "submission_csv_path = '/content/drive/MyDrive/Samsung_AI_challenge/Data/sample_submission.csv'\n",
        "\n",
        "# 기타 경로 설정 : 저장되는 데이터 이름 등 (model, method 에 맞게 설정)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mode 설정 : 어떤 model, 최적화 기법을 사용할 지 정하는 부분 (현재는 GS = Grid Search 만 사용)\n",
        "mode = 'MLP5Hidden' # 사용할 모델 class 이름 : [모델 정의 참조]\n",
        "method = \"GS\" # 사용할 모델 하이퍼파라미터 최적화 알고리즘 이름"
      ],
      "metadata": {
        "id": "4ucCS4iWJwY1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 모델 정의 (필수 실행)"
      ],
      "metadata": {
        "id": "gEB4bnwZj60f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1-1 순수 MLP Linear + ReLU 모델"
      ],
      "metadata": {
        "id": "2ECHOl45t9eZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP - 은닉층 3개"
      ],
      "metadata": {
        "id": "FEEbgqaDvPDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP - 은닉층 3개\n",
        "'''\n",
        "Grid Search 하이퍼파라미터 범위\n",
        "\n",
        "[Epoch 100 기준]\n",
        "param_grid = {\n",
        "    'hidden_sizes': [[64, 128, 64], [128, 256, 128], [32, 64, 32]],\n",
        "    'learning_rate': [0.01, 0.001, 0.0001],\n",
        "    'batch_size': [32, 64, 128],\n",
        "}\n",
        "'''\n",
        "# 현재 최고성능 모델 하이퍼파라미터(GS) : {\"batch_size\": 64, \"hidden_sizes\": [64, 128, 64], \"learning_rate\": 0.01}\n",
        "# Epoch : 500\n",
        "# Top 10% threshold : 92.0392\n",
        "# 제출 성능 : 0.728\n",
        "class MLP3Hidden(nn.Module):\n",
        "    def __init__(self, input_size=11, hidden_sizes=[64, 128, 64], output_size=1):\n",
        "        super(MLP3Hidden, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
        "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
        "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
        "        self.fc4 = nn.Linear(hidden_sizes[2], output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "7cNslOmIk5_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP - 은닉층 4개"
      ],
      "metadata": {
        "id": "tDKQE-3GvWkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP - 은닉층 4개\n",
        "'''\n",
        "Grid Search 하이퍼파라미터 범위\n",
        "\n",
        "'''\n",
        "# 현재 최고성능 모델 하이퍼파라미터(GS) :\n",
        "# Epoch :\n",
        "# Top 10% threshold :\n",
        "# 제출 성능 :\n",
        "class MLP4Hidden(nn.Module):\n",
        "    def __init__(self, input_size=11, hidden_sizes=[64, 128, 64, 32], output_size=1):\n",
        "        super(MLP4Hidden, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
        "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
        "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
        "        self.fc4 = nn.Linear(hidden_sizes[2], hidden_sizes[3])\n",
        "        self.fc5 = nn.Linear(hidden_sizes[3], output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.relu(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "ThyWaZtJvL_v"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP - 은닉층 5개 (best)(0.736)"
      ],
      "metadata": {
        "id": "74A7YgW-vbdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP - 은닉층 5개\n",
        "'''\n",
        "Grid Search 하이퍼파라미터 범위\n",
        "\n",
        "[Epoch 100 기준]\n",
        "param_grid = {\n",
        "    'hidden_sizes': [[64, 128, 128, 64, 32], [128, 256, 256, 128, 64], [32, 64, 64, 32, 16]],\n",
        "    'learning_rate': [0.01, 0.001],\n",
        "    'batch_size': [32, 64, 128],\n",
        "}\n",
        "'''\n",
        "# 현재 최고성능 모델 하이퍼파라미터(GS) : {\"batch_size\": 32, \"hidden_sizes\": [32, 64, 64, 32, 16], \"learning_rate\": 0.001}\n",
        "# Epoch : 93\n",
        "# Top 10% threshold: 92.9191\n",
        "# 제출 성능 : 0.736\n",
        "class MLP5Hidden(nn.Module):\n",
        "    def __init__(self, input_size=11, hidden_sizes=[32, 64, 64, 32, 16], output_size=1):\n",
        "        super(MLP5Hidden, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
        "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
        "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
        "        self.fc4 = nn.Linear(hidden_sizes[2], hidden_sizes[3])\n",
        "        self.fc5 = nn.Linear(hidden_sizes[3], hidden_sizes[4])\n",
        "        self.fc6 = nn.Linear(hidden_sizes[4], output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.relu(self.fc4(x))\n",
        "        x = self.relu(self.fc5(x))\n",
        "        x = self.fc6(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "C26L73cGvY8d"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1-1 MLP Linear + BatchNorm + Dropout + ReLU 모델"
      ],
      "metadata": {
        "id": "GGMNcDKWvulo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP - 은닉층 3개 + BN + Drop"
      ],
      "metadata": {
        "id": "XwbyedQJw9TS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP - 은닉층 3개 + BatchNorm + Dropout\n",
        "'''\n",
        "Grid Search 하이퍼파라미터 범위\n",
        "\n",
        "'''\n",
        "# 현재 최고성능 모델 하이퍼파라미터(GS) :\n",
        "# Epoch :\n",
        "# Top 10% threshold :\n",
        "# 제출 성능 :\n",
        "class MLP3HiddenBnDrop(nn.Module):\n",
        "    def __init__(self, input_size=11, hidden_sizes=[64, 128, 64], output_size=1):\n",
        "        super(MLP3HiddenBnDrop, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_sizes[0])\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_sizes[1])\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
        "        self.bn3 = nn.BatchNorm1d(hidden_sizes[2])\n",
        "        self.dropout3 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc4 = nn.Linear(hidden_sizes[2], output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(self.fc1(x))\n",
        "        x = self.relu(self.dropout1(x))\n",
        "\n",
        "        x = self.bn2(self.fc2(x))\n",
        "        x = self.relu(self.dropout2(x))\n",
        "\n",
        "        x = self.bn3(self.fc3(x))\n",
        "        x = self.relu(self.dropout3(x))\n",
        "\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "N_ZuWQ5Av7xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP - 은닉층 5개 + BN + Drop"
      ],
      "metadata": {
        "id": "OZqr3RLVv1eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP - 은닉층 5개 + BatchNorm + Dropout\n",
        "'''\n",
        "Grid Search 하이퍼파라미터 범위\n",
        "\n",
        "'''\n",
        "# 현재 최고성능 모델 하이퍼파라미터(GS) :\n",
        "# Epoch :\n",
        "# Top 10% threshold :\n",
        "# 제출 성능 :\n",
        "class MLP5HiddenBnDrop(nn.Module):\n",
        "    def __init__(self, input_size=11, hidden_sizes=[64, 128, 64, 32, 16], dropout_rate = 0.5, output_size=1):\n",
        "        super(MLP5HiddenBnDrop, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_sizes[0])\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_sizes[1])\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
        "        self.bn3 = nn.BatchNorm1d(hidden_sizes[2])\n",
        "        self.dropout3 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc4 = nn.Linear(hidden_sizes[2], hidden_sizes[3])\n",
        "        self.bn4 = nn.BatchNorm1d(hidden_sizes[3])\n",
        "        self.dropout4 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc5 = nn.Linear(hidden_sizes[3], hidden_sizes[4])\n",
        "        self.bn5 = nn.BatchNorm1d(hidden_sizes[4])\n",
        "        self.dropout5 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc6 = nn.Linear(hidden_sizes[4], output_size)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(self.fc1(x))\n",
        "        x = self.relu(self.dropout1(x))\n",
        "\n",
        "        x = self.bn2(self.fc2(x))\n",
        "        x = self.relu(self.dropout2(x))\n",
        "\n",
        "        x = self.bn3(self.fc3(x))\n",
        "        x = self.relu(self.dropout3(x))\n",
        "\n",
        "        x = self.bn4(self.fc4(x))\n",
        "        x = self.relu(self.dropout4(x))\n",
        "\n",
        "        x = self.bn5(self.fc5(x))\n",
        "        x = self.relu(self.dropout5(x))\n",
        "\n",
        "        x = self.fc6(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "urMK3xj4vp4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 모델 하이퍼파라미터 최적화 (선택)"
      ],
      "metadata": {
        "id": "2Dxtn9rQxRIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-1. 훈련데이터 -> 훈련+검증 데이터"
      ],
      "metadata": {
        "id": "bItSrRndxX6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터를 훈련 + 검증 데이터로 나누고 train_dataset, val_dataset 을 반환하는 함수\n",
        "def split_dataloader(train_csv_path, val_ratio=0.2, random_state=RANDOM_SEED):\n",
        "    train_data = pd.read_csv(train_csv_path)\n",
        "\n",
        "    X = torch.tensor(train_data.iloc[:,1:-1].values, dtype=torch.float32)\n",
        "    y = torch.tensor(train_data.iloc[:,-1].values, dtype = torch.float32).view(-1,1)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=val_ratio, random_state=random_state)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "    val_dataset = TensorDataset(X_val, y_val)\n",
        "\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "train_dataset, val_dataset = split_dataloader(train_csv_path)"
      ],
      "metadata": {
        "id": "S7oEjp5eyAHu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-2. Grid Search 최적화 알고리즘"
      ],
      "metadata": {
        "id": "DKoiQTtUzc5F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mode 별 하이퍼파라미터 범위 설정"
      ],
      "metadata": {
        "id": "gpHg2FiU0qS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if mode == 'MLP3Hidden':\n",
        "    param_grid = {\n",
        "    'hidden_sizes': [[64, 128, 64], [128, 256, 128], [32, 64, 32]],\n",
        "    'learning_rate': [0.01, 0.001, 0.0001],\n",
        "    'batch_size': [32, 64, 128],\n",
        "    }\n",
        "\n",
        "elif mode == 'MLP4Hidden':\n",
        "    param_grid = {\n",
        "    'hidden_sizes': [[64, 128, 128, 64], [128, 256, 128, 64], [32, 64, 64, 32]],\n",
        "    'learning_rate': [0.01, 0.001],\n",
        "    'batch_size': [32, 64, 128],\n",
        "    }\n",
        "\n",
        "elif mode == 'MLP5Hidden':\n",
        "    param_grid = {\n",
        "    'hidden_sizes': [[64, 128, 128, 64, 32], [128, 256, 256, 128, 64], [32, 64, 64, 32, 16]],\n",
        "    'learning_rate': [0.01, 0.001],\n",
        "    'batch_size': [32, 64, 128],\n",
        "    }\n",
        "\n",
        "with open(f'{mode}_param_grid_range.json', 'w') as json_file:\n",
        "    json.dump(param_grid, json_file)"
      ],
      "metadata": {
        "id": "K2q-zfqb000Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mode 별 탐색을 위한 함수 정의"
      ],
      "metadata": {
        "id": "KXbECUbP1nWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mode_model(mode, hidden_sizes):\n",
        "    if mode == 'MLP3Hidden':\n",
        "        return MLP3Hidden(hidden_sizes=hidden_sizes)\n",
        "    elif mode == 'MLP4Hidden':\n",
        "        return MLP4Hidden(hidden_sizes=hidden_sizes)\n",
        "    elif mode == 'MLP5Hidden':\n",
        "        return MLP5Hidden(hidden_sizes=hidden_sizes)\n",
        "\n",
        "def train_validation_model(mode, hidden_sizes, learning_rate, batch_size):\n",
        "\n",
        "    model = mode_model(mode, hidden_sizes).cuda()\n",
        "    criterion = nn.MSELoss().cuda()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    for epoch in range(100):\n",
        "        model.train()\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            batch_X, batch_y = batch_X.cuda(), batch_y.cuda()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in val_loader:\n",
        "            batch_X, batch_y = batch_X.cuda(), batch_y.cuda()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    MSE = val_loss / len(val_loader)\n",
        "    return MSE\n"
      ],
      "metadata": {
        "id": "IR5yMQVc474A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search 수행"
      ],
      "metadata": {
        "id": "T6fFa4Tf5Gnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_search(parma_grid):\n",
        "    best_params = None\n",
        "    best_MSE = float('inf')\n",
        "\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        MSE = train_validation_model(mode, **params)\n",
        "        print(f\"Testing parameters: {params} => MSE: {MSE:.4f}\")\n",
        "        if MSE < best_MSE:\n",
        "            best_MSE = MSE\n",
        "            best_params = params\n",
        "\n",
        "    return best_params, best_MSE\n",
        "\n",
        "\n",
        "best_params, best_MSE = grid_search(param_grid)\n",
        "print(f'\\nBest parameters: {best_params} with a MSE of {best_MSE:.4f}')\n",
        "\n",
        "with open(f'{mode}_bestparams.json', 'w') as json_file:\n",
        "    json.dump(best_params, json_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "QLXaTm4X5FLd",
        "outputId": "4df3e886-eb84-48ff-c1c2-0c2db4802363"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing parameters: {'batch_size': 32, 'hidden_sizes': [64, 128, 128, 64, 32], 'learning_rate': 0.01} => MSE: 3.7686\n",
            "Testing parameters: {'batch_size': 32, 'hidden_sizes': [64, 128, 128, 64, 32], 'learning_rate': 0.001} => MSE: 3.2252\n",
            "Testing parameters: {'batch_size': 32, 'hidden_sizes': [128, 256, 256, 128, 64], 'learning_rate': 0.01} => MSE: 3.2314\n",
            "Testing parameters: {'batch_size': 32, 'hidden_sizes': [128, 256, 256, 128, 64], 'learning_rate': 0.001} => MSE: 3.2972\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b7d36c49563b>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mbest_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_MSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nBest parameters: {best_params} with a MSE of {best_MSE:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-b7d36c49563b>\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(parma_grid)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_validation_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Testing parameters: {params} => MSE: {MSE:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mMSE\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_MSE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-8039cdc2030c>\u001b[0m in \u001b[0;36mtrain_validation_model\u001b[0;34m(mode, hidden_sizes, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-3 Epoch 최적화(Loss 시각화)"
      ],
      "metadata": {
        "id": "tuDvEydJ69dC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련 함수 정의(loss 리스트 반환)"
      ],
      "metadata": {
        "id": "Ah6TMcv672zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrain_visualize(mode, hidden_sizes, learning_rate, batch_size):\n",
        "\n",
        "    model = mode_model(mode, hidden_sizes).cuda()\n",
        "    criterion = nn.MSELoss().cuda()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(500):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            batch_X, batch_y = batch_X.cuda(), batch_y.cuda()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss = train_loss / len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in val_loader:\n",
        "                batch_X, batch_y = batch_X.cuda(), batch_y.cuda()\n",
        "                outputs = model(batch_X)\n",
        "                loss = criterion(outputs, batch_y)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss = val_loss / len(val_loader)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/100, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "    return train_losses, val_losses"
      ],
      "metadata": {
        "id": "ggxtAs_H73kK"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, val_loss = retrain_visualize(mode, best_params['hidden_sizes'], best_params['learning_rate'], best_params['batch_size'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNXkcNfr9M99",
        "outputId": "3ddd0799-88d0-4e6a-b0b4-ac7989a52367"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Train Loss: 410.2186, Validation Loss: 4.4311\n",
            "Epoch 2/100, Train Loss: 3.5175, Validation Loss: 3.6177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train / validation loss 시각화"
      ],
      "metadata": {
        "id": "pda8AaAo9XYn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "4eMul0RHdfy-",
        "outputId": "75058de0-b81a-4bde-8e2a-7652a5ec9799"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_loss, label='Train Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train and Validation Loss')\n",
        "plt.ylim(0, 8)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(f'{mode}_loss.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 모델 훈련 및 테스트"
      ],
      "metadata": {
        "id": "O-TNs_lB99EV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-1 best param 불러오기 (파일)  "
      ],
      "metadata": {
        "id": "uRdPTK-H-S5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### best parameter 를 파일로 불러오고 싶거나 모델 하이퍼파라미터 최적화 안했을 경우만 실행"
      ],
      "metadata": {
        "id": "D373Xod--nhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_path = \"\"\n",
        "best_params = json.load(open(params_path, 'r'))"
      ],
      "metadata": {
        "id": "s6I6MI7v-58n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-2 DataLoader"
      ],
      "metadata": {
        "id": "My0dfZ6t_NNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_dataloader(train_csv_path):\n",
        "    train_data = pd.read_csv(train_csv_path)\n",
        "\n",
        "    X_train = train_data.iloc[:,1:-1].values\n",
        "    y_train = train_data.iloc[:,-1].values\n",
        "\n",
        "    X_train = torch.tensor(X_train, dtype = torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype = torch.float32).view(-1,1)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "\n",
        "    return train_dataset\n",
        "\n",
        "def test_dataloader(test_csv_path):\n",
        "    test_data = pd.read_csv(test_csv_path)\n",
        "\n",
        "    X_test = pd.read_csv(test_csv_path).iloc[:,1:].values\n",
        "    X_test = torch.tensor(X_test, dtype = torch.float32)\n",
        "\n",
        "    test_dataset = TensorDataset(X_test)\n",
        "\n",
        "    return test_dataset\n",
        "\n",
        "train_dataset = train_dataloader(train_csv_path)\n",
        "test_dataset = test_dataloader(test_csv_path)"
      ],
      "metadata": {
        "id": "AMapvgu8_bFY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-4 Train"
      ],
      "metadata": {
        "id": "9gCIar4JAECo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test(mode, num_epochs, hidden_sizes, learning_rate, batch_size):\n",
        "\n",
        "    model = mode_model(mode, hidden_sizes).cuda()\n",
        "    criterion = nn.MSELoss().cuda()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            batch_X, batch_y = batch_X.cuda(), batch_y.cuda()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        '''\n",
        "        나중에 중간 중간 parameter 저장 예정\n",
        "        '''\n",
        "\n",
        "        train_loss = train_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}')\n",
        "\n",
        "    model_save_path = f\"{mode}_epoch{num_epochs}.pth\"\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "    model.eval()\n",
        "    test_pred = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            batch_X = batch[0].cuda()\n",
        "            outputs = model(batch_X)\n",
        "            test_pred.extend(outputs.cpu().numpy())\n",
        "\n",
        "    test_pred = np.array(test_pred)\n",
        "    return test_pred\n",
        "\n",
        "num_epochs = 100\n",
        "test_pred = train_test(mode, num_epochs, best_params['hidden_sizes'], best_params['learning_rate'], best_params['batch_size'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "8ar9j0zBAPcf",
        "outputId": "eb9999e8-e8b2-45ea-ddde-4058b1a3358f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Train Loss: 367.7600\n",
            "Epoch 2/100, Train Loss: 4.0501\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-a43ceaefd97a>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hidden_sizes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-a43ceaefd97a>\u001b[0m in \u001b[0;36mtrain_test\u001b[0;34m(mode, num_epochs, hidden_sizes, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/decorators.py\u001b[0m in \u001b[0;36mdisable\u001b[0;34m(fn, recursive)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minnermost_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDisableContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDisableContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         if (\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtrace_rules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m             and (\n\u001b[1;32m    412\u001b[0m                 \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__name__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"_call_impl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_wrapped_call_impl\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(obj, is_inlined_call)\u001b[0m\n\u001b[1;32m   3376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3377\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inlined_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3378\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inlined_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskipped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36mcheck_verbose\u001b[0;34m(obj, is_inlined_call)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m     \u001b[0;31m# Consulte the central trace rules defined in torch._dynamo.trace_rules.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m     rule = torch._dynamo.trace_rules.lookup_inner(\n\u001b[0m\u001b[1;32m   3362\u001b[0m         \u001b[0mfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inlined_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36mlookup_inner\u001b[0;34m(obj, name, filename, is_direct_call)\u001b[0m\n\u001b[1;32m   3438\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3440\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mis_aten_op_or_tensor_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTorchInGraphFunctionVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3442\u001b[0m         \u001b[0mrule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_torch_obj_rule_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36mis_aten_op_or_tensor_method\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   2839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2840\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_aten_op_or_tensor_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2841\u001b[0;31m     return obj in get_tensor_method() or isinstance(\n\u001b[0m\u001b[1;32m   2842\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2843\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpOverloadPacket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpOverload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-4 Test"
      ],
      "metadata": {
        "id": "wSBZi6AvBXQW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83-9AKe1rvk9",
        "outputId": "d9138ad0-5bfa-470c-c53d-7bc4d85ba748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10% threshold: 93.3584\n",
            "Number of samples in top 10%: [499]\n"
          ]
        }
      ],
      "source": [
        "# 상위 10% 임계값 계산\n",
        "threshold = np.percentile(test_pred, 90)\n",
        "top_10_percent_mask = test_pred >= threshold\n",
        "\n",
        "# 제출 파일 생성\n",
        "submission_df = pd.read_csv(submission_csv_path)\n",
        "submission_df['y'] = test_pred\n",
        "submission_df.to_csv(f'{mode}_{method}_epoch{num_epochs}.csv', index=False)\n",
        "\n",
        "# 결과 저장\n",
        "log_file_path = 'TOP10_threshold.txt'\n",
        "with open(log_file_path, 'w') as log_file:\n",
        "    log_file.write(f\"Top 10% threshold: {threshold:.4f}\\n\")\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Top 10% threshold: {threshold:.4f}\")\n",
        "print(f\"Number of samples in top 10%: {sum(top_10_percent_mask)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Threshold 가장 높은 값 Test [main]"
      ],
      "metadata": {
        "id": "ShZC-wGDF0aK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "가장 높은 값의 Threshold 를 가지는 Test 결과를 얻을 수 있지만 조금 더 오래걸림.\n",
        "매 epoch 마다 test 진행"
      ],
      "metadata": {
        "id": "4Fy6V7TOGGMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# params 파일로 불러오거나 하이퍼파라미터 최적화 수행 안했을 때만 실행\n",
        "\n",
        "params_path = \"/content/5_layer_MLP_params.json\"\n",
        "best_params = json.load(open(params_path, 'r'))"
      ],
      "metadata": {
        "id": "6PTAlIJJF7nx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ii6gjj0K68R",
        "outputId": "a31d9632-5e3b-4866-a8ff-4a21ae23fa0a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 32,\n",
              " 'hidden_sizes': [32, 64, 64, 32, 16],\n",
              " 'learning_rate': 0.001}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 위에서 정의했으면 안해도 됨\n",
        "mode = 'MLP5Hidden' # 사용할 모델 class 이름 : [모델 정의 참조]\n",
        "method = \"GS\" # 사용할 모델 하이퍼파라미터 최적화 알고리즘 이름"
      ],
      "metadata": {
        "id": "VcfXOuxcKjVv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_dataloader(train_csv_path):\n",
        "    train_data = pd.read_csv(train_csv_path)\n",
        "\n",
        "    X_train = train_data.iloc[:,1:-1].values\n",
        "    y_train = train_data.iloc[:,-1].values\n",
        "\n",
        "    X_train = torch.tensor(X_train, dtype = torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype = torch.float32).view(-1,1)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "\n",
        "    return train_dataset\n",
        "\n",
        "def test_dataloader(test_csv_path):\n",
        "    test_data = pd.read_csv(test_csv_path)\n",
        "\n",
        "    X_test = pd.read_csv(test_csv_path).iloc[:,1:].values\n",
        "    X_test = torch.tensor(X_test, dtype = torch.float32)\n",
        "\n",
        "    test_dataset = TensorDataset(X_test)\n",
        "\n",
        "    return test_dataset\n",
        "\n",
        "train_dataset = train_dataloader(train_csv_path)\n",
        "test_dataset = test_dataloader(test_csv_path)"
      ],
      "metadata": {
        "id": "FCcGtueqGZP4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_test(mode, num_epochs, hidden_sizes, learning_rate, batch_size):\n",
        "\n",
        "    loss_file_path = 'train_loss.txt'\n",
        "    threshold_file_path = 'threshold.txt'\n",
        "    loss_log = open(loss_file_path, 'w')\n",
        "    threshold_log = open(threshold_file_path, 'w')\n",
        "\n",
        "    model = mode_model(mode, hidden_sizes).cuda()\n",
        "    criterion = nn.MSELoss().cuda()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    max_threshold = 0.0\n",
        "    best_epoch = 0\n",
        "    best_pred = None\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            batch_X, batch_y = batch_X.cuda(), batch_y.cuda()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "\n",
        "        train_loss = train_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}')\n",
        "        loss_log.write(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}\\n')\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        test_pred = []\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                batch_X = batch[0].cuda()\n",
        "                outputs = model(batch_X)\n",
        "                test_pred.extend(outputs.cpu().numpy())\n",
        "\n",
        "        test_pred = np.array(test_pred)\n",
        "        threshold = np.percentile(test_pred, 90)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Top 10% threshold: {threshold:.4f}\")\n",
        "        threshold_log.write(f\"Epoch {epoch+1}/{num_epochs}, Top 10% threshold: {threshold:.4f}\\n\")\n",
        "\n",
        "        if threshold > max_threshold:\n",
        "            max_threshold = threshold\n",
        "            best_epoch = epoch+1\n",
        "            best_pred = test_pred\n",
        "\n",
        "    loss_log.close()\n",
        "    threshold_log.close()\n",
        "    return best_pred, best_epoch\n",
        "\n",
        "num_epochs = 100\n",
        "test_pred, best_epoch = get_max_test(mode, num_epochs, best_params['hidden_sizes'], best_params['learning_rate'], best_params['batch_size'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27_SFOneGbvJ",
        "outputId": "64c4e41f-d464-4540-bc58-ddf4c646cbd3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Train Loss: 398.9188\n",
            "Epoch 1/100, Top 10% threshold: 85.2889\n",
            "Epoch 2/100, Train Loss: 3.7590\n",
            "Epoch 2/100, Top 10% threshold: 90.9706\n",
            "Epoch 3/100, Train Loss: 3.2633\n",
            "Epoch 3/100, Top 10% threshold: 91.8073\n",
            "Epoch 4/100, Train Loss: 3.1859\n",
            "Epoch 4/100, Top 10% threshold: 92.6416\n",
            "Epoch 5/100, Train Loss: 3.1796\n",
            "Epoch 5/100, Top 10% threshold: 92.1233\n",
            "Epoch 6/100, Train Loss: 3.1935\n",
            "Epoch 6/100, Top 10% threshold: 91.6764\n",
            "Epoch 7/100, Train Loss: 3.2048\n",
            "Epoch 7/100, Top 10% threshold: 92.2082\n",
            "Epoch 8/100, Train Loss: 3.1726\n",
            "Epoch 8/100, Top 10% threshold: 92.1651\n",
            "Epoch 9/100, Train Loss: 3.1943\n",
            "Epoch 9/100, Top 10% threshold: 92.1772\n",
            "Epoch 10/100, Train Loss: 3.1338\n",
            "Epoch 10/100, Top 10% threshold: 92.0406\n",
            "Epoch 11/100, Train Loss: 3.1512\n",
            "Epoch 11/100, Top 10% threshold: 92.5158\n",
            "Epoch 12/100, Train Loss: 3.1747\n",
            "Epoch 12/100, Top 10% threshold: 91.8615\n",
            "Epoch 13/100, Train Loss: 3.1610\n",
            "Epoch 13/100, Top 10% threshold: 92.1453\n",
            "Epoch 14/100, Train Loss: 3.1196\n",
            "Epoch 14/100, Top 10% threshold: 92.1803\n",
            "Epoch 15/100, Train Loss: 3.1543\n",
            "Epoch 15/100, Top 10% threshold: 92.4156\n",
            "Epoch 16/100, Train Loss: 3.1245\n",
            "Epoch 16/100, Top 10% threshold: 92.5795\n",
            "Epoch 17/100, Train Loss: 3.1736\n",
            "Epoch 17/100, Top 10% threshold: 92.2834\n",
            "Epoch 18/100, Train Loss: 3.1783\n",
            "Epoch 18/100, Top 10% threshold: 91.6801\n",
            "Epoch 19/100, Train Loss: 3.1455\n",
            "Epoch 19/100, Top 10% threshold: 91.8297\n",
            "Epoch 20/100, Train Loss: 3.1353\n",
            "Epoch 20/100, Top 10% threshold: 92.5519\n",
            "Epoch 21/100, Train Loss: 3.0932\n",
            "Epoch 21/100, Top 10% threshold: 91.9255\n",
            "Epoch 22/100, Train Loss: 3.1523\n",
            "Epoch 22/100, Top 10% threshold: 91.8606\n",
            "Epoch 23/100, Train Loss: 3.1122\n",
            "Epoch 23/100, Top 10% threshold: 92.7180\n",
            "Epoch 24/100, Train Loss: 3.1199\n",
            "Epoch 24/100, Top 10% threshold: 91.3485\n",
            "Epoch 25/100, Train Loss: 3.0714\n",
            "Epoch 25/100, Top 10% threshold: 92.6054\n",
            "Epoch 26/100, Train Loss: 3.1361\n",
            "Epoch 26/100, Top 10% threshold: 91.6550\n",
            "Epoch 27/100, Train Loss: 3.1081\n",
            "Epoch 27/100, Top 10% threshold: 92.7513\n",
            "Epoch 28/100, Train Loss: 3.0575\n",
            "Epoch 28/100, Top 10% threshold: 91.5958\n",
            "Epoch 29/100, Train Loss: 3.0505\n",
            "Epoch 29/100, Top 10% threshold: 91.2691\n",
            "Epoch 30/100, Train Loss: 3.1687\n",
            "Epoch 30/100, Top 10% threshold: 92.1604\n",
            "Epoch 31/100, Train Loss: 3.1198\n",
            "Epoch 31/100, Top 10% threshold: 92.6127\n",
            "Epoch 32/100, Train Loss: 3.0933\n",
            "Epoch 32/100, Top 10% threshold: 91.5884\n",
            "Epoch 33/100, Train Loss: 3.0728\n",
            "Epoch 33/100, Top 10% threshold: 92.2350\n",
            "Epoch 34/100, Train Loss: 3.1389\n",
            "Epoch 34/100, Top 10% threshold: 91.8429\n",
            "Epoch 35/100, Train Loss: 3.0903\n",
            "Epoch 35/100, Top 10% threshold: 92.3260\n",
            "Epoch 36/100, Train Loss: 3.1033\n",
            "Epoch 36/100, Top 10% threshold: 91.2504\n",
            "Epoch 37/100, Train Loss: 3.1061\n",
            "Epoch 37/100, Top 10% threshold: 91.6593\n",
            "Epoch 38/100, Train Loss: 3.0850\n",
            "Epoch 38/100, Top 10% threshold: 92.3895\n",
            "Epoch 39/100, Train Loss: 3.0589\n",
            "Epoch 39/100, Top 10% threshold: 91.6603\n",
            "Epoch 40/100, Train Loss: 3.0997\n",
            "Epoch 40/100, Top 10% threshold: 92.8975\n",
            "Epoch 41/100, Train Loss: 3.1478\n",
            "Epoch 41/100, Top 10% threshold: 91.5567\n",
            "Epoch 42/100, Train Loss: 3.0963\n",
            "Epoch 42/100, Top 10% threshold: 91.0834\n",
            "Epoch 43/100, Train Loss: 3.0558\n",
            "Epoch 43/100, Top 10% threshold: 92.3783\n",
            "Epoch 44/100, Train Loss: 3.1431\n",
            "Epoch 44/100, Top 10% threshold: 92.3326\n",
            "Epoch 45/100, Train Loss: 3.1010\n",
            "Epoch 45/100, Top 10% threshold: 92.2794\n",
            "Epoch 46/100, Train Loss: 3.1003\n",
            "Epoch 46/100, Top 10% threshold: 91.4964\n",
            "Epoch 47/100, Train Loss: 3.0595\n",
            "Epoch 47/100, Top 10% threshold: 92.1290\n",
            "Epoch 48/100, Train Loss: 3.0617\n",
            "Epoch 48/100, Top 10% threshold: 91.2630\n",
            "Epoch 49/100, Train Loss: 3.0958\n",
            "Epoch 49/100, Top 10% threshold: 92.4745\n",
            "Epoch 50/100, Train Loss: 3.0604\n",
            "Epoch 50/100, Top 10% threshold: 91.4298\n",
            "Epoch 51/100, Train Loss: 3.0992\n",
            "Epoch 51/100, Top 10% threshold: 92.1161\n",
            "Epoch 52/100, Train Loss: 3.0933\n",
            "Epoch 52/100, Top 10% threshold: 91.7251\n",
            "Epoch 53/100, Train Loss: 3.1149\n",
            "Epoch 53/100, Top 10% threshold: 91.6167\n",
            "Epoch 54/100, Train Loss: 3.1076\n",
            "Epoch 54/100, Top 10% threshold: 92.2741\n",
            "Epoch 55/100, Train Loss: 3.0821\n",
            "Epoch 55/100, Top 10% threshold: 92.3278\n",
            "Epoch 56/100, Train Loss: 3.0549\n",
            "Epoch 56/100, Top 10% threshold: 91.0216\n",
            "Epoch 57/100, Train Loss: 3.0618\n",
            "Epoch 57/100, Top 10% threshold: 92.6304\n",
            "Epoch 58/100, Train Loss: 3.0874\n",
            "Epoch 58/100, Top 10% threshold: 91.1635\n",
            "Epoch 59/100, Train Loss: 3.0870\n",
            "Epoch 59/100, Top 10% threshold: 91.9231\n",
            "Epoch 60/100, Train Loss: 3.0881\n",
            "Epoch 60/100, Top 10% threshold: 91.4201\n",
            "Epoch 61/100, Train Loss: 3.0990\n",
            "Epoch 61/100, Top 10% threshold: 92.8536\n",
            "Epoch 62/100, Train Loss: 3.0707\n",
            "Epoch 62/100, Top 10% threshold: 91.8264\n",
            "Epoch 63/100, Train Loss: 3.0656\n",
            "Epoch 63/100, Top 10% threshold: 91.9596\n",
            "Epoch 64/100, Train Loss: 3.1048\n",
            "Epoch 64/100, Top 10% threshold: 90.9063\n",
            "Epoch 65/100, Train Loss: 3.1200\n",
            "Epoch 65/100, Top 10% threshold: 91.9011\n",
            "Epoch 66/100, Train Loss: 3.0447\n",
            "Epoch 66/100, Top 10% threshold: 93.3584\n",
            "Epoch 67/100, Train Loss: 3.0756\n",
            "Epoch 67/100, Top 10% threshold: 91.1713\n",
            "Epoch 68/100, Train Loss: 3.0721\n",
            "Epoch 68/100, Top 10% threshold: 92.7805\n",
            "Epoch 69/100, Train Loss: 3.0699\n",
            "Epoch 69/100, Top 10% threshold: 92.6470\n",
            "Epoch 70/100, Train Loss: 3.0808\n",
            "Epoch 70/100, Top 10% threshold: 90.9018\n",
            "Epoch 71/100, Train Loss: 3.0738\n",
            "Epoch 71/100, Top 10% threshold: 90.7484\n",
            "Epoch 72/100, Train Loss: 3.0418\n",
            "Epoch 72/100, Top 10% threshold: 92.1919\n",
            "Epoch 73/100, Train Loss: 3.0834\n",
            "Epoch 73/100, Top 10% threshold: 90.7459\n",
            "Epoch 74/100, Train Loss: 3.0196\n",
            "Epoch 74/100, Top 10% threshold: 92.9288\n",
            "Epoch 75/100, Train Loss: 3.0819\n",
            "Epoch 75/100, Top 10% threshold: 91.9677\n",
            "Epoch 76/100, Train Loss: 3.0453\n",
            "Epoch 76/100, Top 10% threshold: 91.7940\n",
            "Epoch 77/100, Train Loss: 3.0612\n",
            "Epoch 77/100, Top 10% threshold: 91.4165\n",
            "Epoch 78/100, Train Loss: 3.0533\n",
            "Epoch 78/100, Top 10% threshold: 91.2254\n",
            "Epoch 79/100, Train Loss: 3.0831\n",
            "Epoch 79/100, Top 10% threshold: 92.9913\n",
            "Epoch 80/100, Train Loss: 3.0614\n",
            "Epoch 80/100, Top 10% threshold: 92.1018\n",
            "Epoch 81/100, Train Loss: 3.0607\n",
            "Epoch 81/100, Top 10% threshold: 92.6926\n",
            "Epoch 82/100, Train Loss: 3.0538\n",
            "Epoch 82/100, Top 10% threshold: 92.4871\n",
            "Epoch 83/100, Train Loss: 3.0548\n",
            "Epoch 83/100, Top 10% threshold: 92.0628\n",
            "Epoch 84/100, Train Loss: 3.0800\n",
            "Epoch 84/100, Top 10% threshold: 92.3913\n",
            "Epoch 85/100, Train Loss: 3.0590\n",
            "Epoch 85/100, Top 10% threshold: 91.4949\n",
            "Epoch 86/100, Train Loss: 3.0713\n",
            "Epoch 86/100, Top 10% threshold: 91.7740\n",
            "Epoch 87/100, Train Loss: 3.0814\n",
            "Epoch 87/100, Top 10% threshold: 91.7495\n",
            "Epoch 88/100, Train Loss: 3.0815\n",
            "Epoch 88/100, Top 10% threshold: 92.4823\n",
            "Epoch 89/100, Train Loss: 3.0418\n",
            "Epoch 89/100, Top 10% threshold: 92.8595\n",
            "Epoch 90/100, Train Loss: 3.0584\n",
            "Epoch 90/100, Top 10% threshold: 92.1831\n",
            "Epoch 91/100, Train Loss: 3.0656\n",
            "Epoch 91/100, Top 10% threshold: 92.0502\n",
            "Epoch 92/100, Train Loss: 3.0422\n",
            "Epoch 92/100, Top 10% threshold: 92.0483\n",
            "Epoch 93/100, Train Loss: 3.0922\n",
            "Epoch 93/100, Top 10% threshold: 91.1140\n",
            "Epoch 94/100, Train Loss: 3.0414\n",
            "Epoch 94/100, Top 10% threshold: 91.7383\n",
            "Epoch 95/100, Train Loss: 3.0505\n",
            "Epoch 95/100, Top 10% threshold: 92.1037\n",
            "Epoch 96/100, Train Loss: 3.0669\n",
            "Epoch 96/100, Top 10% threshold: 91.9932\n",
            "Epoch 97/100, Train Loss: 3.0396\n",
            "Epoch 97/100, Top 10% threshold: 91.9977\n",
            "Epoch 98/100, Train Loss: 3.0789\n",
            "Epoch 98/100, Top 10% threshold: 91.8709\n",
            "Epoch 99/100, Train Loss: 3.0516\n",
            "Epoch 99/100, Top 10% threshold: 92.4301\n",
            "Epoch 100/100, Train Loss: 3.0739\n",
            "Epoch 100/100, Top 10% threshold: 92.4270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 상위 10% 임계값 계산\n",
        "threshold = np.percentile(test_pred, 90)\n",
        "top_10_percent_mask = test_pred >= threshold\n",
        "\n",
        "# 제출 파일 생성\n",
        "submission_df = pd.read_csv(submission_csv_path)\n",
        "submission_df['y'] = test_pred\n",
        "submission_df.to_csv(f'{mode}_{method}_epoch{best_epoch}.csv', index=False)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Top 10% threshold: {threshold:.4f}\")\n",
        "print(f\"Number of samples in top 10%: {sum(top_10_percent_mask)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHAQkQHlKBdK",
        "outputId": "9cb3e527-ed39-4987-9768-ac6c6e115887"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10% threshold: 93.3584\n",
            "Number of samples in top 10%: [499]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}